### 📄 frameworks/nist-genai.md

# NIST Generative AI Profile – Reference Guide

This file introduces the **NIST Generative AI Profile**, a companion to the NIST AI Risk Management Framework (RMF), with a focus on risks and practices specific to generative models like large language models (LLMs).

---

## 📘 Overview
The NIST GenAI Profile extends the AI RMF by offering a tailored set of risk considerations, controls, and outcomes for generative systems, including:
- Synthetic content reliability
- Societal and ethical impacts
- Data provenance and ownership
- Model misuse and over-reliance
- Robustness against adversarial inputs

It reinforces the RMF’s four functions—**Map, Measure, Manage, and Govern**—with examples and outcomes specific to generative AI systems.

---

## 🧩 Example Applications of the Profile
| RMF Function | Generative AI Focus | Examples |
|--------------|---------------------|----------|
| **Map**      | Contextualize use of content-producing systems | Identify risks in using LLMs for financial or legal advice |
| **Measure**  | Monitor outputs for factuality and toxicity     | Use benchmarks to detect hallucinations or bias |
| **Manage**   | Apply layered mitigations and content filters   | Implement RAG pipelines, human-in-the-loop reviews |
| **Govern**   | Define accountability and responsible use       | Publish model cards, enable incident response workflows |

---

## 🎯 How to Use This File
Use this profile to:
- Strengthen framework alignment for LLM use cases beyond generic risk controls
- Justify specific mitigations in the “Framework Alignment” section
- Support internal governance efforts focused on generative models

---

> **This file serves as an evolving companion to the AI RMF—focused on the unique risks and responsibilities of deploying generative AI systems in enterprise settings.**
